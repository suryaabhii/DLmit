{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPY+kR9VDYwLDYz4dfdoNa4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4zcRzI9B3gE4","executionInfo":{"status":"ok","timestamp":1730994079982,"user_tz":-330,"elapsed":6914504,"user":{"displayName":"abhijeet surya","userId":"17506844210145583727"}},"outputId":"647ad82a-cd39-4d99-e673-c52db1cd5cfb"},"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n","\u001b[1m170498071/170498071\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 0us/step\n","Epoch 1/10\n","\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m689s\u001b[0m 440ms/step - accuracy: 0.4404 - loss: 1.6112 - val_accuracy: 0.5521 - val_loss: 1.2862\n","Epoch 2/10\n","\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m703s\u001b[0m 415ms/step - accuracy: 0.5737 - loss: 1.2174 - val_accuracy: 0.5735 - val_loss: 1.2208\n","Epoch 3/10\n","\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m718s\u001b[0m 438ms/step - accuracy: 0.5966 - loss: 1.1660 - val_accuracy: 0.5785 - val_loss: 1.1999\n","Epoch 4/10\n","\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m706s\u001b[0m 415ms/step - accuracy: 0.6026 - loss: 1.1366 - val_accuracy: 0.5890 - val_loss: 1.1825\n","Epoch 5/10\n","\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m649s\u001b[0m 415ms/step - accuracy: 0.6118 - loss: 1.1121 - val_accuracy: 0.5828 - val_loss: 1.2004\n","Epoch 6/10\n","\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m681s\u001b[0m 415ms/step - accuracy: 0.6166 - loss: 1.0943 - val_accuracy: 0.5961 - val_loss: 1.1656\n","Epoch 7/10\n","\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m682s\u001b[0m 415ms/step - accuracy: 0.6248 - loss: 1.0721 - val_accuracy: 0.5972 - val_loss: 1.1510\n","Epoch 8/10\n","\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m682s\u001b[0m 415ms/step - accuracy: 0.6340 - loss: 1.0562 - val_accuracy: 0.5959 - val_loss: 1.1523\n","Epoch 9/10\n","\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m682s\u001b[0m 414ms/step - accuracy: 0.6361 - loss: 1.0435 - val_accuracy: 0.5989 - val_loss: 1.1443\n","Epoch 10/10\n","\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m683s\u001b[0m 415ms/step - accuracy: 0.6361 - loss: 1.0380 - val_accuracy: 0.6037 - val_loss: 1.1429\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.src.callbacks.history.History at 0x7ffa8170b460>"]},"metadata":{},"execution_count":2}],"source":["import tensorflow as tf\n","from tensorflow.keras.applications import VGG16\n","from tensorflow.keras.layers import GlobalAveragePooling2D, Dense\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.datasets import cifar10\n","from tensorflow.keras.utils import to_categorical\n","\n","# Load the CIFAR-10 dataset\n","(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n","\n","# Normalize the data (scale pixel values to the range [0, 1])\n","x_train = x_train.astype('float32') / 255.0\n","x_test = x_test.astype('float32') / 255.0\n","\n","# Convert labels to one-hot encoding (if using categorical crossentropy loss)\n","y_train = y_train.flatten()  # Flatten the labels (CIFAR-10 labels are in shape (n, 1))\n","y_test = y_test.flatten()\n","\n","# Load pre-trained VGG16 model\n","base_model = VGG16(weights='imagenet', include_top=False, input_shape=(32, 32, 3))\n","for layer in base_model.layers:\n","    layer.trainable = False  # Freeze base model layers\n","\n","# Add custom layers on top of VGG16\n","x = base_model.output\n","x = GlobalAveragePooling2D()(x)\n","x = Dense(64, activation='relu')(x)\n","predictions = Dense(10, activation='softmax')(x)\n","\n","# Compile the model\n","model = Model(inputs=base_model.input, outputs=predictions)\n","model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n","\n","# Train the model\n","model.fit(x_train, y_train, epochs=10, validation_data=(x_test, y_test))\n"]}]}